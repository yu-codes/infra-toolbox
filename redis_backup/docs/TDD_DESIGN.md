# Redis Backup Service - TDD æ¸¬è©¦è¨­è¨ˆæ–‡ä»¶

> æ­¤æ–‡ä»¶æ ¹æ“š DDD è¨­è¨ˆä½¿ç”¨ [BDD-DDD-TDD SKILL](../../skills/skills/bdd-ddd-tdd/SKILL.md) æ–¹æ³•è«–ç”Ÿæˆ

---

## 1. æ¸¬è©¦ç­–ç•¥

### æ¸¬è©¦é‡‘å­—å¡”

```mermaid
graph TB
    subgraph Pyramid["æ¸¬è©¦é‡‘å­—å¡”"]
        E2E["ğŸ”º ç«¯å°ç«¯æ¸¬è©¦ (E2E)<br/>10% - Docker Compose æ•´åˆ"]
        INT["ğŸ”¸ æ•´åˆæ¸¬è©¦<br/>30% - API + Redis + Storage"]
        UNIT["ğŸŸ¢ å–®å…ƒæ¸¬è©¦<br/>60% - é ˜åŸŸé‚è¼¯"]
    end
    
    E2E --> INT --> UNIT
```

### æ¸¬è©¦è¦†è“‹ç‡ç›®æ¨™

| å±¤ç´š | ç›®æ¨™è¦†è“‹ç‡ | èªªæ˜ |
|-----|-----------|------|
| é ˜åŸŸå±¤ (Domain) | >= 90% | æ¥­å‹™é‚è¼¯æ ¸å¿ƒ |
| æ‡‰ç”¨å±¤ (Application) | >= 80% | ç”¨ä¾‹å”èª¿ |
| åŸºç¤è¨­æ–½å±¤ (Infrastructure) | >= 60% | å¤–éƒ¨æ•´åˆ |
| API å±¤ | >= 70% | ç«¯é»è™•ç† |

---

## 2. å–®å…ƒæ¸¬è©¦è¨­è¨ˆ

### 2.1 å€¼ç‰©ä»¶æ¸¬è©¦ (Value Objects)

#### Schedule å€¼ç‰©ä»¶

```python
# tests/unit/domain/test_schedule.py

class TestSchedule:
    """Schedule å€¼ç‰©ä»¶æ¸¬è©¦"""
    
    # --- å»ºæ§‹æ¸¬è©¦ ---
    
    def test_should_create_schedule_with_valid_cron_expression(self):
        """æ‡‰è©²ä½¿ç”¨æœ‰æ•ˆçš„ Cron è¡¨é”å¼å»ºç«‹ Schedule"""
        # Arrange
        cron_expr = "0 2 * * *"
        
        # Act
        schedule = Schedule(expression=cron_expr)
        
        # Assert
        assert schedule.expression == cron_expr
    
    def test_should_reject_invalid_cron_expression(self):
        """æ‡‰è©²æ‹’çµ•ç„¡æ•ˆçš„ Cron è¡¨é”å¼"""
        # Arrange
        invalid_expr = "invalid"
        
        # Act & Assert
        with pytest.raises(InvalidCronExpressionError):
            Schedule(expression=invalid_expr)
    
    # --- è¡Œç‚ºæ¸¬è©¦ ---
    
    def test_should_return_true_when_time_matches_schedule(self):
        """ç•¶æ™‚é–“ç¬¦åˆæ’ç¨‹æ™‚æ‡‰è©²è¿”å› True"""
        # Arrange
        schedule = Schedule(expression="0 2 * * *")  # æ¯æ—¥å‡Œæ™¨ 2 é»
        check_time = datetime(2024, 1, 1, 2, 0, 0)
        
        # Act
        result = schedule.is_triggered_at(check_time)
        
        # Assert
        assert result is True
    
    def test_should_return_false_when_time_not_matches(self):
        """ç•¶æ™‚é–“ä¸ç¬¦åˆæ’ç¨‹æ™‚æ‡‰è©²è¿”å› False"""
        # Arrange
        schedule = Schedule(expression="0 2 * * *")
        check_time = datetime(2024, 1, 1, 3, 0, 0)
        
        # Act
        result = schedule.is_triggered_at(check_time)
        
        # Assert
        assert result is False
    
    def test_should_calculate_next_trigger_time(self):
        """æ‡‰è©²è¨ˆç®—ä¸‹ä¸€æ¬¡è§¸ç™¼æ™‚é–“"""
        # Arrange
        schedule = Schedule(expression="0 2 * * *")
        current_time = datetime(2024, 1, 1, 10, 0, 0)
        
        # Act
        next_time = schedule.get_next_trigger_time(after=current_time)
        
        # Assert
        assert next_time == datetime(2024, 1, 2, 2, 0, 0)
```

#### RedisConnection å€¼ç‰©ä»¶

```python
# tests/unit/domain/test_redis_connection.py

class TestRedisConnection:
    """RedisConnection å€¼ç‰©ä»¶æ¸¬è©¦"""
    
    def test_should_create_connection_with_valid_config(self):
        """æ‡‰è©²ä½¿ç”¨æœ‰æ•ˆé…ç½®å»ºç«‹é€£ç·š"""
        # Arrange & Act
        conn = RedisConnection(
            host="localhost",
            port=6379,
            password="secret",
            database=0
        )
        
        # Assert
        assert conn.host == "localhost"
        assert conn.port == 6379
    
    def test_should_reject_invalid_port(self):
        """æ‡‰è©²æ‹’çµ•ç„¡æ•ˆçš„ port"""
        # Act & Assert
        with pytest.raises(InvalidPortError):
            RedisConnection(host="localhost", port=-1)
    
    def test_should_create_connection_string(self):
        """æ‡‰è©²ç”Ÿæˆæ­£ç¢ºçš„é€£ç·šå­—ä¸²"""
        # Arrange
        conn = RedisConnection(host="localhost", port=6379, database=0)
        
        # Act
        conn_str = conn.to_connection_string()
        
        # Assert
        assert conn_str == "redis://localhost:6379/0"
```

#### BackupFile å€¼ç‰©ä»¶

```python
# tests/unit/domain/test_backup_file.py

class TestBackupFile:
    """BackupFile å€¼ç‰©ä»¶æ¸¬è©¦"""
    
    def test_should_generate_filename_with_timestamp(self):
        """æ‡‰è©²ç”Ÿæˆå¸¶æ™‚é–“æˆ³çš„æª”æ¡ˆåç¨±"""
        # Arrange
        timestamp = datetime(2024, 1, 15, 2, 30, 45)
        
        # Act
        file = BackupFile.create(timestamp=timestamp)
        
        # Assert
        assert file.filename == "redis_backup_20240115_023045.rdb"
    
    def test_should_include_label_in_filename(self):
        """æ‡‰è©²åœ¨æª”æ¡ˆåç¨±ä¸­åŒ…å«æ¨™ç±¤"""
        # Arrange
        timestamp = datetime(2024, 1, 15, 2, 30, 45)
        label = "pre-migration"
        
        # Act
        file = BackupFile.create(timestamp=timestamp, label=label)
        
        # Assert
        assert file.filename == "redis_backup_20240115_023045_pre-migration.rdb"
    
    def test_should_validate_checksum(self):
        """æ‡‰è©²é©—è­‰æ ¡é©—ç¢¼"""
        # Arrange
        file = BackupFile(
            filename="test.rdb",
            path="/backups/test.rdb",
            size=1024,
            checksum="abc123"
        )
        
        # Act
        is_valid = file.validate_checksum("abc123")
        
        # Assert
        assert is_valid is True
```

### 2.2 å¯¦é«”æ¸¬è©¦ (Entities)

#### BackupRecord å¯¦é«”

```python
# tests/unit/domain/test_backup_record.py

class TestBackupRecord:
    """BackupRecord å¯¦é«”æ¸¬è©¦"""
    
    def test_should_create_record_with_in_progress_status(self):
        """å»ºç«‹æ™‚æ‡‰è©²æ˜¯ IN_PROGRESS ç‹€æ…‹"""
        # Arrange & Act
        record = BackupRecord.create(
            job_id=JobId("job-1"),
            trigger_type=TriggerType.SCHEDULED
        )
        
        # Assert
        assert record.status == BackupStatus.IN_PROGRESS
        assert record.start_time is not None
    
    def test_should_complete_record_with_file_info(self):
        """å®Œæˆæ™‚æ‡‰è©²åŒ…å«æª”æ¡ˆè³‡è¨Š"""
        # Arrange
        record = BackupRecord.create(job_id=JobId("job-1"))
        file = BackupFile(
            filename="backup.rdb",
            path="/backups/backup.rdb",
            size=1024,
            checksum="abc123"
        )
        
        # Act
        record.complete(file=file)
        
        # Assert
        assert record.status == BackupStatus.COMPLETED
        assert record.file == file
        assert record.end_time is not None
    
    def test_should_fail_record_with_error_info(self):
        """å¤±æ•—æ™‚æ‡‰è©²åŒ…å«éŒ¯èª¤è³‡è¨Š"""
        # Arrange
        record = BackupRecord.create(job_id=JobId("job-1"))
        error = ErrorInfo(
            code="REDIS_CONNECTION_ERROR",
            message="Cannot connect to Redis"
        )
        
        # Act
        record.fail(error=error)
        
        # Assert
        assert record.status == BackupStatus.FAILED
        assert record.error_info == error
    
    def test_should_not_change_completed_status(self):
        """å·²å®Œæˆçš„è¨˜éŒ„ä¸æ‡‰è©²å†è®Šæ›´ç‹€æ…‹"""
        # Arrange
        record = BackupRecord.create(job_id=JobId("job-1"))
        record.complete(file=create_mock_file())
        
        # Act & Assert
        with pytest.raises(InvalidStateTransitionError):
            record.fail(error=ErrorInfo(code="ERROR", message="error"))
    
    def test_should_calculate_duration(self):
        """æ‡‰è©²è¨ˆç®—å‚™ä»½æŒçºŒæ™‚é–“"""
        # Arrange
        record = BackupRecord.create(job_id=JobId("job-1"))
        record._start_time = datetime(2024, 1, 1, 2, 0, 0)
        record._end_time = datetime(2024, 1, 1, 2, 5, 30)
        
        # Act
        duration = record.calculate_duration()
        
        # Assert
        assert duration == timedelta(minutes=5, seconds=30)
    
    def test_should_mark_as_important(self):
        """æ‡‰è©²æ¨™è¨˜ç‚ºé‡è¦"""
        # Arrange
        record = BackupRecord.create(job_id=JobId("job-1"))
        record.complete(file=create_mock_file())
        
        # Act
        record.mark_as_important()
        
        # Assert
        assert record.metadata.is_important is True
```

### 2.3 èšåˆæ ¹æ¸¬è©¦ (Aggregate Roots)

#### BackupJob èšåˆæ ¹

```python
# tests/unit/domain/test_backup_job.py

class TestBackupJob:
    """BackupJob èšåˆæ ¹æ¸¬è©¦"""
    
    # --- å»ºæ§‹æ¸¬è©¦ ---
    
    def test_should_create_job_with_idle_status(self):
        """å»ºç«‹æ™‚æ‡‰è©²æ˜¯ IDLE ç‹€æ…‹"""
        # Arrange & Act
        job = BackupJob.create(
            schedule=Schedule("0 2 * * *"),
            connection=create_mock_connection(),
            storage=create_mock_storage()
        )
        
        # Assert
        assert job.status == JobStatus.IDLE
    
    # --- åŸ·è¡Œæ¸¬è©¦ ---
    
    def test_should_execute_when_conditions_met(self):
        """æ¢ä»¶æ»¿è¶³æ™‚æ‡‰è©²åŸ·è¡Œå‚™ä»½"""
        # Arrange
        job = BackupJob.create(
            schedule=Schedule("0 2 * * *"),
            connection=create_connected_mock(),
            storage=create_storage_with_space()
        )
        
        # Act
        record = job.execute()
        
        # Assert
        assert job.status == JobStatus.RUNNING
        assert record is not None
    
    def test_should_not_execute_when_already_running(self):
        """å·²åœ¨åŸ·è¡Œæ™‚ä¸æ‡‰è©²å†æ¬¡åŸ·è¡Œ"""
        # Arrange
        job = BackupJob.create(...)
        job._status = JobStatus.RUNNING
        
        # Act & Assert
        with pytest.raises(JobAlreadyRunningError):
            job.execute()
    
    def test_should_not_execute_when_redis_disconnected(self):
        """Redis æ–·ç·šæ™‚ä¸æ‡‰è©²åŸ·è¡Œ"""
        # Arrange
        disconnected = create_disconnected_mock()
        job = BackupJob.create(connection=disconnected, ...)
        
        # Act & Assert
        with pytest.raises(RedisConnectionError):
            job.execute()
    
    def test_should_not_execute_when_storage_full(self):
        """å„²å­˜ç©ºé–“ä¸è¶³æ™‚ä¸æ‡‰è©²åŸ·è¡Œ"""
        # Arrange
        full_storage = create_storage_without_space()
        job = BackupJob.create(storage=full_storage, ...)
        
        # Act & Assert
        with pytest.raises(InsufficientStorageError):
            job.execute()
    
    # --- æ’ç¨‹æ¸¬è©¦ ---
    
    def test_should_trigger_at_scheduled_time(self):
        """æ‡‰è©²åœ¨æ’ç¨‹æ™‚é–“è§¸ç™¼"""
        # Arrange
        job = BackupJob.create(schedule=Schedule("0 2 * * *"), ...)
        check_time = datetime(2024, 1, 1, 2, 0, 0)
        
        # Act
        should_run = job.should_execute_at(check_time)
        
        # Assert
        assert should_run is True
    
    def test_should_reschedule(self):
        """æ‡‰è©²å¯ä»¥é‡æ–°è¨­å®šæ’ç¨‹"""
        # Arrange
        job = BackupJob.create(schedule=Schedule("0 2 * * *"), ...)
        new_schedule = Schedule("0 */6 * * *")
        
        # Act
        job.reschedule(new_schedule)
        
        # Assert
        assert job.schedule == new_schedule
```

#### RetentionPolicy èšåˆæ ¹

```python
# tests/unit/domain/test_retention_policy.py

class TestRetentionPolicy:
    """RetentionPolicy èšåˆæ ¹æ¸¬è©¦"""
    
    def test_should_create_policy_with_valid_config(self):
        """æ‡‰è©²ä½¿ç”¨æœ‰æ•ˆé…ç½®å»ºç«‹ç­–ç•¥"""
        # Arrange & Act
        policy = RetentionPolicy.create(
            retention_days=7,
            max_backups=30,
            min_backups=3
        )
        
        # Assert
        assert policy.retention_days == 7
        assert policy.max_backups == 30
        assert policy.min_backups == 3
    
    def test_should_reject_min_backups_greater_than_max(self):
        """min_backups ä¸æ‡‰è©²å¤§æ–¼ max_backups"""
        # Act & Assert
        with pytest.raises(InvalidPolicyError):
            RetentionPolicy.create(
                retention_days=7,
                max_backups=3,
                min_backups=5
            )
    
    def test_should_identify_expired_backups(self):
        """æ‡‰è©²è­˜åˆ¥éæœŸå‚™ä»½"""
        # Arrange
        policy = RetentionPolicy.create(retention_days=7, ...)
        now = datetime(2024, 1, 15)
        
        backups = [
            create_backup_record(created_at=datetime(2024, 1, 1)),   # éæœŸ
            create_backup_record(created_at=datetime(2024, 1, 5)),   # éæœŸ
            create_backup_record(created_at=datetime(2024, 1, 10)),  # æœ‰æ•ˆ
            create_backup_record(created_at=datetime(2024, 1, 14)),  # æœ‰æ•ˆ
        ]
        
        # Act
        plan = policy.evaluate(backups, current_time=now)
        
        # Assert
        assert len(plan.to_delete) == 2
        assert len(plan.to_keep) == 2
    
    def test_should_keep_minimum_backups(self):
        """æ‡‰è©²ä¿ç•™æœ€å°‘æ•¸é‡çš„å‚™ä»½"""
        # Arrange
        policy = RetentionPolicy.create(
            retention_days=7,
            min_backups=3
        )
        now = datetime(2024, 1, 15)
        
        # æ‰€æœ‰å‚™ä»½éƒ½éæœŸï¼Œä½†åªæœ‰ 3 å€‹
        backups = [
            create_backup_record(created_at=datetime(2024, 1, 1)),
            create_backup_record(created_at=datetime(2024, 1, 2)),
            create_backup_record(created_at=datetime(2024, 1, 3)),
        ]
        
        # Act
        plan = policy.evaluate(backups, current_time=now)
        
        # Assert
        assert len(plan.to_delete) == 0  # ä¸åˆªé™¤ä»»ä½•å‚™ä»½
        assert len(plan.to_keep) == 3
    
    def test_should_delete_oldest_when_exceeds_max(self):
        """è¶…éæœ€å¤§æ•¸é‡æ™‚æ‡‰è©²åˆªé™¤æœ€èˆŠçš„"""
        # Arrange
        policy = RetentionPolicy.create(max_backups=3, ...)
        
        backups = [
            create_backup_record(created_at=datetime(2024, 1, 1)),  # æœ€èˆŠ - åˆªé™¤
            create_backup_record(created_at=datetime(2024, 1, 2)),  # åˆªé™¤
            create_backup_record(created_at=datetime(2024, 1, 3)),
            create_backup_record(created_at=datetime(2024, 1, 4)),
            create_backup_record(created_at=datetime(2024, 1, 5)),  # æœ€æ–°
        ]
        
        # Act
        plan = policy.evaluate(backups)
        
        # Assert
        assert len(plan.to_delete) == 2
    
    def test_should_protect_important_backups(self):
        """æ‡‰è©²ä¿è­·é‡è¦å‚™ä»½"""
        # Arrange
        policy = RetentionPolicy.create(
            retention_days=7,
            protected_labels=["important", "pre-migration"]
        )
        now = datetime(2024, 1, 15)
        
        important_backup = create_backup_record(
            created_at=datetime(2024, 1, 1),  # éæœŸ
            label="pre-migration"
        )
        
        # Act
        plan = policy.evaluate([important_backup], current_time=now)
        
        # Assert
        assert len(plan.to_delete) == 0
        assert important_backup.id in [b.id for b in plan.to_keep]
```

### 2.4 é ˜åŸŸæœå‹™æ¸¬è©¦ (Domain Services)

#### BackupExecutionService

```python
# tests/unit/domain/services/test_backup_execution_service.py

class TestBackupExecutionService:
    """BackupExecutionService é ˜åŸŸæœå‹™æ¸¬è©¦"""
    
    @pytest.fixture
    def service(self, mock_redis_client, mock_file_system):
        return BackupExecutionService(
            redis_client=mock_redis_client,
            file_system=mock_file_system
        )
    
    def test_should_execute_bgsave_command(self, service, mock_redis_client):
        """æ‡‰è©²åŸ·è¡Œ BGSAVE å‘½ä»¤"""
        # Arrange
        mock_redis_client.bgsave.return_value = True
        
        # Act
        service.execute_backup()
        
        # Assert
        mock_redis_client.bgsave.assert_called_once()
    
    def test_should_wait_for_rdb_file_completion(self, service, mock_redis_client):
        """æ‡‰è©²ç­‰å¾… RDB æª”æ¡ˆç”Ÿæˆå®Œæˆ"""
        # Arrange
        mock_redis_client.lastsave.side_effect = [
            datetime(2024, 1, 1, 1, 0, 0),  # èˆŠçš„æ™‚é–“æˆ³
            datetime(2024, 1, 1, 1, 0, 0),  # ä»æ˜¯èˆŠçš„
            datetime(2024, 1, 1, 2, 0, 0),  # æ–°çš„æ™‚é–“æˆ³ - å®Œæˆ
        ]
        
        # Act
        result = service.wait_for_backup_completion(timeout=30)
        
        # Assert
        assert result is True
        assert mock_redis_client.lastsave.call_count == 3
    
    def test_should_timeout_when_backup_takes_too_long(self, service, mock_redis_client):
        """å‚™ä»½æ™‚é–“éé•·æ™‚æ‡‰è©²è¶…æ™‚"""
        # Arrange
        mock_redis_client.lastsave.return_value = datetime(2024, 1, 1, 1, 0, 0)
        
        # Act & Assert
        with pytest.raises(BackupTimeoutError):
            service.wait_for_backup_completion(timeout=1)
    
    def test_should_copy_rdb_to_backup_path(self, service, mock_file_system):
        """æ‡‰è©²è¤‡è£½ RDB æª”æ¡ˆåˆ°å‚™ä»½ç›®éŒ„"""
        # Arrange
        source = "/var/lib/redis/dump.rdb"
        destination = "/backups/redis_backup_20240101_020000.rdb"
        
        # Act
        service.copy_backup(source, destination)
        
        # Assert
        mock_file_system.copy.assert_called_with(source, destination)
    
    def test_should_calculate_file_checksum(self, service, mock_file_system):
        """æ‡‰è©²è¨ˆç®—æª”æ¡ˆæ ¡é©—ç¢¼"""
        # Arrange
        mock_file_system.calculate_md5.return_value = "abc123"
        
        # Act
        checksum = service.calculate_checksum("/backups/test.rdb")
        
        # Assert
        assert checksum == "abc123"
```

### 2.5 é ˜åŸŸäº‹ä»¶æ¸¬è©¦ (Domain Events)

```python
# tests/unit/domain/events/test_backup_events.py

class TestBackupEvents:
    """å‚™ä»½é ˜åŸŸäº‹ä»¶æ¸¬è©¦"""
    
    def test_backup_completed_event_should_contain_required_data(self):
        """BackupCompleted äº‹ä»¶æ‡‰è©²åŒ…å«å¿…è¦è³‡æ–™"""
        # Arrange
        record = create_completed_backup_record()
        
        # Act
        event = BackupCompleted.from_record(record)
        
        # Assert
        assert event.record_id == record.id
        assert event.job_id == record.job_id
        assert event.file_name == record.file.filename
        assert event.size == record.file.size
        assert event.duration == record.calculate_duration()
        assert event.timestamp is not None
    
    def test_backup_failed_event_should_contain_error_info(self):
        """BackupFailed äº‹ä»¶æ‡‰è©²åŒ…å«éŒ¯èª¤è³‡è¨Š"""
        # Arrange
        job_id = JobId("job-1")
        error = ErrorInfo(code="ERROR", message="Connection failed")
        
        # Act
        event = BackupFailed(job_id=job_id, error_info=error, retry_count=2)
        
        # Assert
        assert event.job_id == job_id
        assert event.error_info == error
        assert event.retry_count == 2
```

---

## 3. æ•´åˆæ¸¬è©¦è¨­è¨ˆ

### 3.1 API æ•´åˆæ¸¬è©¦

```python
# tests/integration/api/test_backup_api.py

class TestBackupAPI:
    """å‚™ä»½ API æ•´åˆæ¸¬è©¦"""
    
    @pytest.fixture
    def client(self, app):
        return TestClient(app)
    
    def test_trigger_backup_should_return_202(self, client, mock_backup_job):
        """è§¸ç™¼å‚™ä»½æ‡‰è©²è¿”å› 202"""
        # Arrange
        mock_backup_job.status = JobStatus.IDLE
        
        # Act
        response = client.post("/api/v1/backup/trigger")
        
        # Assert
        assert response.status_code == 202
        assert "task_id" in response.json()
    
    def test_trigger_backup_should_return_409_when_running(self, client, mock_backup_job):
        """å‚™ä»½åŸ·è¡Œä¸­æ™‚æ‡‰è©²è¿”å› 409"""
        # Arrange
        mock_backup_job.status = JobStatus.RUNNING
        
        # Act
        response = client.post("/api/v1/backup/trigger")
        
        # Assert
        assert response.status_code == 409
    
    def test_get_backup_status_should_return_task_info(self, client):
        """å–å¾—å‚™ä»½ç‹€æ…‹æ‡‰è©²è¿”å›ä»»å‹™è³‡è¨Š"""
        # Act
        response = client.get("/api/v1/backup/status/task-123")
        
        # Assert
        assert response.status_code == 200
        data = response.json()
        assert "status" in data
        assert "start_time" in data
        assert "progress" in data
    
    def test_list_backups_should_return_all_backups(self, client, mock_repository):
        """åˆ—å‡ºå‚™ä»½æ‡‰è©²è¿”å›æ‰€æœ‰å‚™ä»½"""
        # Arrange
        mock_repository.find_all.return_value = [
            create_backup_record(),
            create_backup_record(),
        ]
        
        # Act
        response = client.get("/api/v1/backups")
        
        # Assert
        assert response.status_code == 200
        assert len(response.json()["backups"]) == 2
```

### 3.2 Redis æ•´åˆæ¸¬è©¦

```python
# tests/integration/infrastructure/test_redis_client.py

@pytest.mark.integration
class TestRedisClientIntegration:
    """Redis å®¢æˆ¶ç«¯æ•´åˆæ¸¬è©¦"""
    
    @pytest.fixture
    def redis_client(self, redis_container):
        return RedisClientAdapter(
            host=redis_container.host,
            port=redis_container.port
        )
    
    def test_should_connect_to_redis(self, redis_client):
        """æ‡‰è©²é€£ç·šåˆ° Redis"""
        # Act
        is_connected = redis_client.test_connection()
        
        # Assert
        assert is_connected is True
    
    def test_should_execute_bgsave(self, redis_client):
        """æ‡‰è©²åŸ·è¡Œ BGSAVE"""
        # Act
        result = redis_client.bgsave()
        
        # Assert
        assert result is True
    
    def test_should_get_rdb_path(self, redis_client):
        """æ‡‰è©²å–å¾— RDB æª”æ¡ˆè·¯å¾‘"""
        # Act
        path = redis_client.get_rdb_path()
        
        # Assert
        assert path.endswith(".rdb")
```

### 3.3 å„²å­˜æ•´åˆæ¸¬è©¦

```python
# tests/integration/infrastructure/test_file_storage.py

@pytest.mark.integration
class TestFileStorageIntegration:
    """æª”æ¡ˆå„²å­˜æ•´åˆæ¸¬è©¦"""
    
    @pytest.fixture
    def storage(self, tmp_path):
        return FileStorageAdapter(backup_path=str(tmp_path))
    
    def test_should_save_backup_file(self, storage, tmp_path):
        """æ‡‰è©²å„²å­˜å‚™ä»½æª”æ¡ˆ"""
        # Arrange
        source_file = tmp_path / "source.rdb"
        source_file.write_bytes(b"test content")
        
        # Act
        result = storage.save(
            source=str(source_file),
            filename="backup.rdb"
        )
        
        # Assert
        assert result.exists()
    
    def test_should_list_backups(self, storage, tmp_path):
        """æ‡‰è©²åˆ—å‡ºå‚™ä»½"""
        # Arrange
        (tmp_path / "backup1.rdb").touch()
        (tmp_path / "backup2.rdb").touch()
        
        # Act
        backups = storage.list_backups()
        
        # Assert
        assert len(backups) == 2
    
    def test_should_check_available_space(self, storage):
        """æ‡‰è©²æª¢æŸ¥å¯ç”¨ç©ºé–“"""
        # Act
        space = storage.get_available_space()
        
        # Assert
        assert space > 0
```

---

## 4. ç«¯å°ç«¯æ¸¬è©¦è¨­è¨ˆ

```python
# tests/e2e/test_backup_workflow.py

@pytest.mark.e2e
class TestBackupWorkflowE2E:
    """å‚™ä»½å·¥ä½œæµç¨‹ç«¯å°ç«¯æ¸¬è©¦"""
    
    @pytest.fixture(scope="class")
    def docker_compose(self):
        """å•Ÿå‹• Docker Compose ç’°å¢ƒ"""
        compose = DockerCompose("docker-compose.test.yml")
        compose.up()
        yield compose
        compose.down()
    
    def test_complete_backup_workflow(self, docker_compose, api_client):
        """å®Œæ•´å‚™ä»½å·¥ä½œæµç¨‹æ¸¬è©¦"""
        # Step 1: æª¢æŸ¥å¥åº·ç‹€æ…‹
        health = api_client.get("/health")
        assert health.json()["status"] == "healthy"
        
        # Step 2: è§¸ç™¼å‚™ä»½
        trigger_response = api_client.post("/api/v1/backup/trigger")
        assert trigger_response.status_code == 202
        task_id = trigger_response.json()["task_id"]
        
        # Step 3: ç­‰å¾…å‚™ä»½å®Œæˆ
        for _ in range(30):
            status = api_client.get(f"/api/v1/backup/status/{task_id}")
            if status.json()["status"] == "COMPLETED":
                break
            time.sleep(1)
        
        assert status.json()["status"] == "COMPLETED"
        
        # Step 4: ç¢ºèªå‚™ä»½æª”æ¡ˆå­˜åœ¨
        backups = api_client.get("/api/v1/backups")
        assert len(backups.json()["backups"]) >= 1
    
    def test_restore_from_backup(self, docker_compose, api_client):
        """å¾å‚™ä»½é‚„åŸæ¸¬è©¦"""
        # Step 1: å–å¾—å‚™ä»½åˆ—è¡¨
        backups = api_client.get("/api/v1/backups")
        backup_file = backups.json()["backups"][0]["filename"]
        
        # Step 2: åŸ·è¡Œé‚„åŸ
        restore_response = api_client.post(
            "/api/v1/restore",
            json={"backup_file": backup_file}
        )
        assert restore_response.status_code == 200
        
        # Step 3: é©—è­‰é‚„åŸçµæœ
        result = restore_response.json()
        assert result["status"] == "COMPLETED"
        assert result["validation"]["is_valid"] is True
```

---

## 5. æ¸¬è©¦æ¡ˆä¾‹è¿½è¹¤è¡¨

### 5.1 å€¼ç‰©ä»¶æ¸¬è©¦

| æ¸¬è©¦æ¡ˆä¾‹ | ç›®æ¨™ç‰©ä»¶ | ç‹€æ…‹ |
|---------|---------|------|
| æœ‰æ•ˆ Cron è¡¨é”å¼å»ºç«‹ Schedule | Schedule | â¬œ |
| ç„¡æ•ˆ Cron è¡¨é”å¼æ‹’çµ• | Schedule | â¬œ |
| æ™‚é–“ç¬¦åˆæ’ç¨‹åˆ¤æ–· | Schedule | â¬œ |
| è¨ˆç®—ä¸‹æ¬¡è§¸ç™¼æ™‚é–“ | Schedule | â¬œ |
| æœ‰æ•ˆé€£ç·šé…ç½®å»ºç«‹ | RedisConnection | â¬œ |
| ç„¡æ•ˆ port æ‹’çµ• | RedisConnection | â¬œ |
| ç”Ÿæˆå¸¶æ™‚é–“æˆ³æª”å | BackupFile | â¬œ |
| å¸¶æ¨™ç±¤çš„æª”å | BackupFile | â¬œ |
| æ ¡é©—ç¢¼é©—è­‰ | BackupFile | â¬œ |

### 5.2 å¯¦é«”æ¸¬è©¦

| æ¸¬è©¦æ¡ˆä¾‹ | ç›®æ¨™ç‰©ä»¶ | ç‹€æ…‹ |
|---------|---------|------|
| å»ºç«‹æ™‚ IN_PROGRESS ç‹€æ…‹ | BackupRecord | â¬œ |
| å®Œæˆæ™‚åŒ…å«æª”æ¡ˆè³‡è¨Š | BackupRecord | â¬œ |
| å¤±æ•—æ™‚åŒ…å«éŒ¯èª¤è³‡è¨Š | BackupRecord | â¬œ |
| å·²å®Œæˆä¸å¯å†è®Šæ›´ | BackupRecord | â¬œ |
| è¨ˆç®—æŒçºŒæ™‚é–“ | BackupRecord | â¬œ |
| æ¨™è¨˜ç‚ºé‡è¦ | BackupRecord | â¬œ |

### 5.3 èšåˆæ ¹æ¸¬è©¦

| æ¸¬è©¦æ¡ˆä¾‹ | ç›®æ¨™ç‰©ä»¶ | ç‹€æ…‹ |
|---------|---------|------|
| å»ºç«‹æ™‚ IDLE ç‹€æ…‹ | BackupJob | â¬œ |
| æ¢ä»¶æ»¿è¶³æ™‚åŸ·è¡Œ | BackupJob | â¬œ |
| åŸ·è¡Œä¸­ä¸å¯å†åŸ·è¡Œ | BackupJob | â¬œ |
| Redis æ–·ç·šä¸åŸ·è¡Œ | BackupJob | â¬œ |
| ç©ºé–“ä¸è¶³ä¸åŸ·è¡Œ | BackupJob | â¬œ |
| æ’ç¨‹æ™‚é–“è§¸ç™¼ | BackupJob | â¬œ |
| é‡æ–°è¨­å®šæ’ç¨‹ | BackupJob | â¬œ |
| è­˜åˆ¥éæœŸå‚™ä»½ | RetentionPolicy | â¬œ |
| ä¿ç•™æœ€å°‘å‚™ä»½ | RetentionPolicy | â¬œ |
| è¶…éæœ€å¤§æ•¸é‡åˆªé™¤æœ€èˆŠ | RetentionPolicy | â¬œ |
| ä¿è­·é‡è¦å‚™ä»½ | RetentionPolicy | â¬œ |

### 5.4 é ˜åŸŸæœå‹™æ¸¬è©¦

| æ¸¬è©¦æ¡ˆä¾‹ | ç›®æ¨™æœå‹™ | ç‹€æ…‹ |
|---------|---------|------|
| åŸ·è¡Œ BGSAVE | BackupExecutionService | â¬œ |
| ç­‰å¾… RDB å®Œæˆ | BackupExecutionService | â¬œ |
| å‚™ä»½è¶…æ™‚ | BackupExecutionService | â¬œ |
| è¤‡è£½åˆ°å‚™ä»½ç›®éŒ„ | BackupExecutionService | â¬œ |
| è¨ˆç®—æ ¡é©—ç¢¼ | BackupExecutionService | â¬œ |

### 5.5 æ•´åˆæ¸¬è©¦

| æ¸¬è©¦æ¡ˆä¾‹ | ç›®æ¨™ | ç‹€æ…‹ |
|---------|------|------|
| è§¸ç™¼å‚™ä»½è¿”å› 202 | Backup API | â¬œ |
| åŸ·è¡Œä¸­è¿”å› 409 | Backup API | â¬œ |
| å–å¾—å‚™ä»½ç‹€æ…‹ | Backup API | â¬œ |
| åˆ—å‡ºæ‰€æœ‰å‚™ä»½ | Backup API | â¬œ |
| é€£ç·š Redis | Redis Client | â¬œ |
| åŸ·è¡Œ BGSAVE | Redis Client | â¬œ |
| å„²å­˜å‚™ä»½æª”æ¡ˆ | File Storage | â¬œ |
| åˆ—å‡ºå‚™ä»½ | File Storage | â¬œ |

### 5.6 ç«¯å°ç«¯æ¸¬è©¦

| æ¸¬è©¦æ¡ˆä¾‹ | ç‹€æ…‹ |
|---------|------|
| å®Œæ•´å‚™ä»½å·¥ä½œæµç¨‹ | â¬œ |
| å¾å‚™ä»½é‚„åŸ | â¬œ |

---

## 6. æ¸¬è©¦åŸ·è¡ŒæŒ‡ä»¤

```bash
# åŸ·è¡Œæ‰€æœ‰å–®å…ƒæ¸¬è©¦
pytest tests/unit -v

# åŸ·è¡Œç‰¹å®šæ¨¡çµ„æ¸¬è©¦
pytest tests/unit/domain/test_backup_job.py -v

# åŸ·è¡Œæ•´åˆæ¸¬è©¦ï¼ˆéœ€è¦ Dockerï¼‰
pytest tests/integration -v -m integration

# åŸ·è¡Œç«¯å°ç«¯æ¸¬è©¦
pytest tests/e2e -v -m e2e

# åŸ·è¡Œæ¸¬è©¦ä¸¦ç”Ÿæˆè¦†è“‹ç‡å ±å‘Š
pytest --cov=src --cov-report=html tests/

# åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦
pytest tests/ -v
```

---

## 7. Mock èˆ‡ Fixture è¨­è¨ˆ

```python
# tests/conftest.py

@pytest.fixture
def mock_redis_client():
    """Mock Redis å®¢æˆ¶ç«¯"""
    client = Mock(spec=IRedisClient)
    client.test_connection.return_value = True
    client.bgsave.return_value = True
    return client

@pytest.fixture
def mock_file_system():
    """Mock æª”æ¡ˆç³»çµ±"""
    fs = Mock(spec=IFileSystem)
    fs.copy.return_value = True
    fs.get_available_space.return_value = 10 * 1024 * 1024 * 1024  # 10GB
    return fs

@pytest.fixture
def create_backup_record():
    """å»ºç«‹æ¸¬è©¦ç”¨ BackupRecord çš„å·¥å» å‡½å¼"""
    def _create(
        job_id: str = "job-1",
        status: BackupStatus = BackupStatus.COMPLETED,
        created_at: datetime = None,
        label: str = None
    ) -> BackupRecord:
        record = BackupRecord.create(
            job_id=JobId(job_id),
            trigger_type=TriggerType.SCHEDULED
        )
        if status == BackupStatus.COMPLETED:
            record.complete(file=create_mock_file(label=label))
        if created_at:
            record._start_time = created_at
        return record
    return _create
```
